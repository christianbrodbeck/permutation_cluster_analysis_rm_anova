{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main question is how to calculate permutation test with repeated measures (RM) anova using different clusters (per-defined groups of channels). Similar to the MNE function: https://martinos.org/mne/stable/generated/mne.stats.permutation_cluster_test.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\Anaconda3\\envs\\mne\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "from gc import collect as clear\n",
    "from eelbrain import *\n",
    "\n",
    "try:\n",
    "    if \"winsound\" not in sys.modules:\n",
    "        import winsound\n",
    "    def makeSound(freq = 6000, # Hz\n",
    "              duration = 3000): # millisecond\n",
    "        winsound.Beep(freq, duration)\n",
    "except ImportError:\n",
    "    if \"os\" not in sys.modules:\n",
    "        import winsound\n",
    "    def makeSound():\n",
    "        os.system('say -v Amir''s Task finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing sample data with pandas.\n",
    "\n",
    "It's 60 files (~260kb per file). 3 groups, 10 couples, 2 repeated measures. \n",
    "\n",
    "To make it simple I used balanced design. My real data is unbalanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first two columns represents the channels' name\n",
    "2. alpha/beta/gamma represents the PLV values for the pair of channels\n",
    "3. id - couples' number\n",
    "4. group - 1/2/3 the group condition. Between subjects. \n",
    "5. measure - m/f the first/second measure. Within subjects, my repeated measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my shape is: (60, 6, 3844) (file, columns(channel_1, channel_2, alpha, id, group, measure), plv values)\n",
      "[['Fp1-0' 'Fp1-0' 'Fp1-0' ... 'O2-1' 'O2-1' 'O2-1']\n",
      " ['Fp1-0' 'Fp2-0' 'F7-0' ... 'P8-1' 'O1-1' 'O2-1']\n",
      " [0.0 0.31032640154038965 -0.2362711853195596 ... -0.042475196670743925\n",
      "  0.7321402521589316 0.0]\n",
      " [130.0 130.0 130.0 ... 130.0 130.0 130.0]\n",
      " ['rc' 'rc' 'rc' ... 'rc' 'rc' 'rc']\n",
      " ['f' 'f' 'f' ... 'f' 'f' 'f']]\n"
     ]
    }
   ],
   "source": [
    "files = [x[0]+\"/\"+f for x in os.walk(\"data\") for f in x[2] if\n",
    "               f.endswith(\".csv\")] \n",
    "\n",
    "chnames = ['Fp1-0', 'Fp2-0', 'F7-0', 'F8-0', 'F3-0', 'F4-0', 'Fz-0', 'FT9-0', 'FT10-0', 'FC5-0', 'FC1-0',\n",
    " 'FC2-0', 'FC6-0', 'T7-0', 'C3-0', 'Cz-0', 'C4-0', 'T8-0', 'TP9-0', 'CP5-0', 'CP1-0', 'CP2-0',\n",
    " 'CP6-0', 'TP10-0',  'P7-0', 'P3-0', 'Pz-0', 'P4-0', 'P8-0', 'O1-0', 'O2-0', 'Fp1-1', 'Fp2-1',\n",
    " 'F7-1', 'F8-1', 'F3-1', 'F4-1', 'Fz-1', 'FT9-1', 'FT10-1', 'FC5-1', 'FC1-1', 'FC2-1', 'FC6-1',\n",
    " 'T7-1', 'C3-1', 'Cz-1', 'C4-1', 'T8-1', 'TP9-1', 'CP5-1', 'CP1-1', 'CP2-1',  'CP6-1',  'TP10-1',\n",
    " 'P7-1',  'P3-1',  'Pz-1',  'P4-1',  'P8-1',  'O1-1', 'O2-1']\n",
    "\n",
    "fs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, usecols=['channel_1', 'channel_2', \"alpha\"], header=0).assign(id = pd.to_numeric(os.path.basename(file)[1:4]), group = pd.to_numeric(os.path.basename(file)[1]), measure = os.path.basename(file)[5])\n",
    "    df[[\"channel_1\",\"channel_2\"]] = df[[\"channel_1\",\"channel_2\"]].replace(list(range(62)), chnames)\n",
    "    df[[\"group\"]] = df[[\"group\"]].replace([1, 2, 3], [\"rc\", \"bf\", \"st\"])\n",
    "    df[[\"id\"]] = df[[\"id\"]].astype(float)\n",
    "    df = np.expand_dims(df, axis = 0)\n",
    "    fs.append(df)\n",
    "\n",
    "fs = np.transpose(np.concatenate(fs, axis=0), (0, 2, 1))\n",
    "\n",
    "print(\"my shape is:\", fs.shape, \"(file, columns(channel_1, channel_2, alpha, id, group, measure), plv values)\")\n",
    "\n",
    "print(fs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting channel names from numeric to actual names, changing group names to string, and changing id type to float.\n",
    "\n",
    "The suffix -0 or -1 reflects if it is the first or second participant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Starting to use *eelbrain**.\n",
    "\n",
    "Creating `ds()` object from my pandas Data.Frame. For string columns I used `factor`, for numeric columns I used `NDVar`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allowed connectivities between sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "connectivity = pd.read_csv(\"connectivity.csv\")\n",
    "connectivity = connectivity[[\"ch1\", \"ch2\"]]\n",
    "connectivity = connectivity.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connectivity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "connectivity array needs to be integer type, got object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f2a50b02bea4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msensor_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategorial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sensor\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnectivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\eelbrain\\_data_obj.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, values, connectivity)\u001b[0m\n\u001b[0;32m   7583\u001b[0m             raise ValueError(\"All Categorial values must be strings; got %r.\" %\n\u001b[0;32m   7584\u001b[0m                              (self.values,))\n\u001b[1;32m-> 7585\u001b[1;33m         \u001b[0mDimension\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnectivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7587\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mne\\lib\\site-packages\\eelbrain\\_data_obj.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, connectivity)\u001b[0m\n\u001b[0;32m   7020\u001b[0m                 \u001b[0mconnectivity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnectivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7021\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mconnectivity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'i'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7022\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"connectivity array needs to be integer type, got {connectivity.dtype}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7023\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mconnectivity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnectivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7024\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"connectivity requires shape (n_edges, 2), got array with shape {connectivity.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: connectivity array needs to be integer type, got object"
     ]
    }
   ],
   "source": [
    "sensor_dim = Categorial(\"sensor\", chnames, connectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "\n",
    "for cl, ct in zip(fs.columns, fs.dtypes.values):\n",
    "    if ct != \"object\":\n",
    "        ds[cl] = NDVar(fs[cl].values, dims = (Case))\n",
    "    else:\n",
    "        ds[cl] = Factor(fs[cl].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning memory\n",
    "del files, fs, cl, chnames\n",
    "clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic info about my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.summary())\n",
    "print(ds.head(5))\n",
    "print(ds.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I understood correctly, I should use the `info` attribute to create my clusters.\n",
    "\n",
    "So, let's say I have three clusters for the following channels: \n",
    "1. F4 and F3\n",
    "2. T7, CP5, and P7\n",
    "3. CP6, T8, and P8\n",
    "\n",
    "How can I add and use these clusters? If I want to see if F4*-0* (in my first participant) is related to F3*-1* (in my second participant)? or T7*-0* is related to T7*-1*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular RM anova for the data. While it's a bit redundant, I wanted to see that I can run it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.anova(ds[\"alpha\"], ds[\"group\"] * ds[\"measure\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I moved to permutation RM anova with clusters. \n",
    "1. I understand that I have some issues with the way I build the NDVar for `id`. I didn't understand how to fix it. \n",
    "2. How should I specify the cluster?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testnd.anova(ds[\"alpha\"], ds[\"group\"] * ds[\"measure\"] * ds[\"id\"], match=False, samples=100, title=\"RM with permutation:\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
